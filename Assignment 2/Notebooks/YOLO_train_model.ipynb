{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO_train_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCM5ypKytsUDxF1ndR0RHG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Based on this tutorial:\n","\n","https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/"],"metadata":{"id":"OIn-XTMx_vds"}},{"cell_type":"markdown","source":["# Training and testing a YOLO model\n","This jupiter notebook trains a YOLOv5 model using the images from the \"train\" folder given in the assignment.\n","\n","The training images was split from being 50 train images to 40 train and 10 validation images.\n","\n","This is mainly only to show that I have trained and that it works. I haved a my trained model to the .zip file that will be run in testing."],"metadata":{"id":"4_NEzg05E-3l"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"WngipvOEE8Wp"}},{"cell_type":"markdown","source":["Only 3 thing needs to be done:\n","1. Make sure that no other sessions is running and run this using GPU.\n","1. Mount the google drive.\n","3. Have the .zip file in the root directory of your google drive or specify the path in the !unzip.\n","\n","The time of training this model depends on amount of iterations set. To save the model make sure the \"want_to_save\" = true. The model will save to google drive when finished. If \"want_to_save\" = false it will not save the model but only show that its training a model. Its not necessary to save it because the Bildenalyse_assignment2_resources.zip already comes with my trained model."],"metadata":{"id":"y6me1rH7MVR_"}},{"cell_type":"code","source":["want_to_save_model = False # If true the model is saved to your google drive after the training is done. Else it will not be saved."],"metadata":{"id":"LJzm9ruEAKl_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-I0-n-g4_qQF","executionInfo":{"status":"ok","timestamp":1647674158468,"user_tz":-60,"elapsed":2118,"user":{"displayName":"Simon Myhre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12715988124642427687"}},"outputId":"bbe80c2f-b6a5-48cf-b9e8-0a28b68e0613"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","ln: failed to create symbolic link '/mydrive/My Drive': File exists\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive"]},{"cell_type":"code","source":["import os.path\n","from os import path\n","if path.exists(\"/content/Bildeanalyse-assignment2-resources\") == False:\n","  !unzip /mydrive/Bildeanalyse-assignment2-resources.zip -d ./"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cg7CQ0rDEyRH","executionInfo":{"status":"ok","timestamp":1647674171686,"user_tz":-60,"elapsed":13224,"user":{"displayName":"Simon Myhre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12715988124642427687"}},"outputId":"0fec632a-06f1-4465-808d-4ba5de92a00a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /mydrive/Bildeanalyse-assignment2-resources.zip\n","replace ./__MACOSX/._Bildeanalyse-assignment2-resources? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}]},{"cell_type":"markdown","source":["## The code"],"metadata":{"id":"XX5SwtU6FFrB"}},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # clone repo\n","!pip install -U -r yolov5/requirements.txt  # install dependencies\n","\n","%cd /content/yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBcW6YRpFHlp","executionInfo":{"status":"ok","timestamp":1647674182142,"user_tz":-60,"elapsed":10461,"user":{"displayName":"Simon Myhre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12715988124642427687"}},"outputId":"61a0986b-e809-4148-9d59-00f560dd7f57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 4)) (3.5.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 6)) (4.5.5.64)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 7)) (9.0.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 9)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 10)) (1.7.3)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 11)) (1.11.0)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 12)) (0.12.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 13)) (4.63.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 16)) (2.8.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 20)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 21)) (0.11.2)\n","Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 37)) (0.0.31.post2005241907)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (4.31.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2021.10.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 11)) (3.10.0.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (57.4.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.44.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.37.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.3.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 20)) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.2.0)\n","/content/yolov5\n"]}]},{"cell_type":"code","source":["import torch\n","from IPython.display import Image  # for displaying images\n","\n","print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJyuai7ZFsIF","executionInfo":{"status":"ok","timestamp":1647674183115,"user_tz":-60,"elapsed":985,"user":{"displayName":"Simon Myhre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12715988124642427687"}},"outputId":"97a0401a-235f-4c71-d724-fed11cbf932f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch 1.11.0+cu102 _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"]}]},{"cell_type":"code","source":["!python train.py --img 608 --batch 16 --epochs 150 --data /content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/data.yaml --weights yolov5s.pt --cache"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcgoFE6uGGpr","executionInfo":{"status":"ok","timestamp":1647674401763,"user_tz":-60,"elapsed":44593,"user":{"displayName":"Simon Myhre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12715988124642427687"}},"outputId":"2e8d83b1-5887-44cb-c064-08a1262c8ea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=150, batch_size=16, imgsz=608, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.1-39-g4effd06 torch 1.11.0+cu102 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 77.2MB/s]\n","\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.8 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/train/labels' images and labels...40 found, 0 missing, 0 empty, 0 corrupt: 100% 40/40 [00:00<00:00, 330.53it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 40/40 [00:00<00:00, 197.28it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/valid/labels' images and labels...10 found, 0 missing, 0 empty, 0 corrupt: 100% 10/10 [00:00<00:00, 175.39it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Bildeanalyse-assignment2-resources/yolo/Images-yolo-annotated/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 10/10 [00:00<00:00, 78.11it/s]\n","Plotting labels to runs/train/exp/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.65 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 608 train, 608 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 150 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     0/149     2.91G    0.1092   0.03099         0        16       608: 100% 3/3 [00:04<00:00,  1.55s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n","                 all         10         14     0.0169      0.286    0.00993    0.00182\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     1/149     2.91G    0.1215   0.03223         0        22       608: 100% 3/3 [00:02<00:00,  1.27it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.93it/s]\n","                 all         10         14      0.037     0.0714     0.0134      0.002\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     2/149     2.91G    0.1187   0.03197         0        23       608: 100% 3/3 [00:02<00:00,  1.27it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.99it/s]\n","                 all         10         14     0.0121      0.357    0.00621     0.0012\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     3/149     2.91G    0.1186   0.02955         0        31       608: 100% 3/3 [00:02<00:00,  1.27it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.23it/s]\n","                 all         10         14     0.0125      0.143    0.00638    0.00139\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     4/149     2.91G    0.1103   0.03113         0        20       608: 100% 3/3 [00:02<00:00,  1.28it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.46it/s]\n","                 all         10         14     0.0105      0.429    0.00769    0.00135\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     5/149     2.91G    0.1083   0.02992         0        23       608: 100% 3/3 [00:02<00:00,  1.28it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.61it/s]\n","                 all         10         14     0.0109      0.286    0.00762    0.00137\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     6/149     2.91G    0.1041   0.02789         0        47       608:  33% 1/3 [00:01<00:03,  1.84s/it]\n","Traceback (most recent call last):\n","  File \"train.py\", line 643, in <module>\n","    main(opt)\n","  File \"train.py\", line 539, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"train.py\", line 354, in train\n","    f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1]))\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["outputs = glob.glob(\"/content/yolov5/runs/train/*\")\n","last_output = outputs[len(outputs)-1] + \"/weights/best.pt\"\n","if want_to_save_model == True:\n","  !cp -av $last_output /mydrive/yolo_model/"],"metadata":{"id":"e32-lDH6KIyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you want to use the model you just saved you can find it in the yolo_model folder on your google drive. Take this \"best.pt\" file and racplace it with the one in \"/content/Bildeanalyse-assignment2-resources/yolo/model/\""],"metadata":{"id":"FSA0ZJtTGcnG"}}]}